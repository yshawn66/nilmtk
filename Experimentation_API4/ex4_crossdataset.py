# å®éªŒ3ï¼šè·¨æ•°æ®é›†4ç®—æ³•æ€§èƒ½å¤§æ¯”æ‹¼
from nilmtk.api import API
from nilmtk.disaggregate import CO, Mean, FHMMExact, Hart85
import warnings
import os
import pandas as pd

warnings.filterwarnings("ignore")

print("ğŸš€ å®éªŒ3ï¼šè·¨æ•°æ®é›†4ç®—æ³•æ€§èƒ½å¤§æ¯”æ‹¼")
print("è®­ç»ƒ: REDDæ•°æ®é›† (ç¾å›½) â†’ æµ‹è¯•: UK-DALEæ•°æ®é›† (è‹±å›½)")
print("ç®—æ³•: Mean, CO, FHMM, Hart85")
print("ç›®æ ‡è®¾å¤‡: fridge, microwave, dish washer")
print("è¯„ä¼°æŒ‡æ ‡: MAE + RMSE")
print("-" * 60)

# è·¨æ•°æ®é›†å®éªŒé…ç½®
experiment3_cross = {
    'power': {'mains': ['apparent'], 'appliance': ['active']},
    'sample_rate': 60,
    'appliances': ['fridge', 'microwave', 'dish washer'],  # ä¸¤ä¸ªæ•°æ®é›†éƒ½æœ‰çš„è®¾å¤‡
    'methods': {
        "Mean": Mean({}),
        "CO": CO({}),
        "FHMM": FHMMExact({'num_of_states': 2}),
        "Hart85": Hart85({})
    },
    'train': {
        'datasets': {
            'REDD': {
                'path': os.path.join('..', 'data', 'redd_low.h5'),
                'buildings': {
                    1: {'start_time': '2011-04-20', 'end_time': '2011-05-01'},
                    2: {'start_time': '2011-04-20', 'end_time': '2011-05-01'}
                }
            }
        }
    },
    'test': {
        'datasets': {
            'UKDALE': {  # è·¨æ•°æ®é›†æµ‹è¯•ï¼
                'path': os.path.join('..', 'data', 'ukdale.h5'),
                'buildings': {
                    1: {'start_time': '2013-05-01', 'end_time': '2013-05-02'}
                }
            }
        },
        'metrics': ['mae', 'rmse']
    }
}

print("æ­£åœ¨è¿è¡Œè·¨æ•°æ®é›†4ç®—æ³•æ¯”è¾ƒ...")
try:
    results = API(experiment3_cross)

    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print("\nğŸ“Š è·¨æ•°æ®é›†æ€§èƒ½ç»“æœ:")
    for i, error_df in enumerate(results.errors):
        metric = results.errors_keys[i].split('_')[-1]
        print(f"\n{metric.upper()} ç»“æœ (REDDè®­ç»ƒ â†’ UK-DALEæµ‹è¯•):")
        print(error_df.round(2))

    # è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›åˆ†æ
    print("\nğŸŒ è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›æ’å:")
    mae_df = results.errors[0]

    # è®¡ç®—æ¯ä¸ªç®—æ³•çš„å¹³å‡MAE
    avg_performance = mae_df.mean().sort_values()

    for i, (algo, avg_mae) in enumerate(avg_performance.items(), 1):
        if avg_mae < 30:
            level = "ğŸŸ¢ ä¼˜ç§€"
        elif avg_mae < 50:
            level = "ğŸŸ¡ è‰¯å¥½"
        else:
            level = "ğŸ”´ éœ€æ”¹è¿›"
        print(f"  {i}. {algo:6}: å¹³å‡MAE {avg_mae:.2f} {level}")

    # å„è®¾å¤‡æœ€ä½³ç®—æ³•
    print(f"\nğŸ† å„è®¾å¤‡è·¨æ•°æ®é›†æœ€ä½³ç®—æ³•:")
    for appliance in mae_df.index:
        best = mae_df.loc[appliance].idxmin()
        value = mae_df.loc[appliance].min()
        print(f"  {appliance:12}: {best:6} (MAE: {value:.2f})")

    # è·¨æ•°æ®é›†æŒ‘æˆ˜åˆ†æ
    print(f"\nğŸ’¡ è·¨æ•°æ®é›†æŒ‘æˆ˜åˆ†æ:")
    print(f"  ğŸ“ åœ°ç†å·®å¼‚: ç¾å›½ vs è‹±å›½ç”¨ç”µä¹ æƒ¯")
    print(f"  ğŸ  å»ºç­‘å·®å¼‚: ä¸åŒæˆ¿å±‹ç»“æ„å’Œè®¾å¤‡")
    print(f"  âš¡ ç”µç½‘å·®å¼‚: ä¸åŒç”µå‹å’Œé¢‘ç‡æ ‡å‡†")
    print(f"  ğŸ“Š æ•°æ®å·®å¼‚: ä¸åŒé‡‡æ ·ç‡å’Œæ ‡æ³¨æ–¹å¼")

    print("\nâœ… è·¨æ•°æ®é›†4ç®—æ³•æ¯”è¾ƒå®Œæˆï¼")
    print("ğŸ’¡ è¿™æ˜¯çœŸæ­£è€ƒéªŒç®—æ³•æ³›åŒ–èƒ½åŠ›çš„ç»ˆææµ‹è¯•ï¼")

except Exception as e:
    print(f"âŒ å®éªŒå¤±è´¥: {e}")
    print("ğŸ’¡ æç¤º: ç¡®ä¿UK-DALEæ•°æ®é›†å·²ä¸‹è½½")

    # å¤‡é€‰æ–¹æ¡ˆï¼šREDDå†…éƒ¨è·¨å»ºç­‘
    print("\nğŸ”„ å¤‡é€‰æ–¹æ¡ˆ: REDDå†…éƒ¨è·¨å»ºç­‘æµ‹è¯•")
    experiment3_backup = experiment3_cross.copy()
    experiment3_backup['test']['datasets'] = {
        'REDD': {
            'path': os.path.join('..', 'data', 'redd_low.h5'),
            'buildings': {
                3: {'start_time': '2011-04-18', 'end_time': '2011-04-20'},
                4: {'start_time': '2011-04-18', 'end_time': '2011-04-20'}
            }
        }
    }

    try:
        print("è¿è¡ŒREDDè·¨å»ºç­‘æµ‹è¯•...")
        results_backup = API(experiment3_backup)

        for i, error_df in enumerate(results_backup.errors):
            metric = results_backup.errors_keys[i].split('_')[-1]
            print(f"\n{metric.upper()} (è·¨å»ºç­‘):")
            print(error_df.round(2))

    except Exception as e2:
        print(f"å¤‡é€‰æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
